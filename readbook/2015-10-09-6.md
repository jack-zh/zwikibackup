title: 《Hadoop MapReduce实战手册》 -目录
tags: 

### 第1章 搭建Hadoop并在集群中运行	1
	1.1 简介	1
	1.2 在你的机器上安装Hadoop	2
	1.3 写WordCountMapReduce示例程序，打包并使用独立的Hadoop运行它	3
	1.4 给WordCount MapReduce程序增加combiner步骤	7
	1.5 安装HDFS	8
	1.6 使用HDFS监控UI	11
	1.7 HDFS的基本命令行文件操作	12
	1.8 在分布式集群环境中设置Hadoop	14
	1.9 在分布式集群环境中运行WordCount程序	18
	1.10 使用MapReduce监控UI	20

### 第2章 HDFS进阶	21
	2.1 简介	21
	2.2 HDFS基准测试	22
	2.3 添加一个新的DataNode	23
	2.4 DataNode下架	25
	2.5 使用多个磁盘/卷以及限制HDFS的磁盘使用情况	26
	2.6 设置HDFS块大小	27
	2.7 设置文件冗余因子	28
	2.8 使用HDFS的Java API	29
	2.9 使用HDFS的C API（libhdfs）	33
	2.10 挂载HDFS（Fuse-DFS）	36
	2.11 在HDFS中合并文件	38

### 第3章 高级Hadoop MapReduce运维	40
	3.1 简介	40
	3.2 调优集群部署的Hadoop配置	40
	3.3 运行基准测试来验证Hadoop的安装	43
	3.4 复用Java虚拟机以提高性能	44
	3.5 容错和推测执行	45
	3.6 调试脚本—分析任务失败	46
	3.7 设置失败百分比以及跳过不良记录	48
	3.8 共享用户的Hadoop集群—使用公平调度器和其他调度器	50
	3.9 Hadoop的安全性——整合使用Kerberos	51
	3.10 使用Hadoop的工具接口	56

### 第4章 开发复杂的Hadoop MapReduce应用程序	59
	4.1 简介	59
	4.2 选择合适的Hadoop数据类型	60
	4.3 实现自定义的Hadoop Writable数据类型	62
	4.4 实现自定义Hadoop key类型	65
	4.5 从mapper中输出不同值类型的数据	68
	4.6 为输入数据格式选择合适的Hadoop InputFormat	70
	4.7 添加新的输入数据格式的支持—实现自定义的InputFormat	73
	4.8 格式化MapReduce计算的结果—使用Hadoop的OutputFormat	76
	4.9 Hadoop的中间（map到reduce）数据分区	78
	4.10 将共享资源传播和分发到MapReduce作业的任务中—Hadoop DistributedCache	80
	4.11 在Hadoop上使用传统应用程序—Hadoop Streaming	84
	4.12 添加MapReduce作业之间的依赖关系	86
	4.13 用于报告自定义指标的Hadoop计数器	88

### 第5章 Hadoop生态系统	90
	5.1 简介	90
	5.2 安装HBase	91
	5.3 使用Java客户端API随机存取数据	93
	5.4 基于HBase（表输入/输出）运行MapReduce作业	95
	5.5 安装Pig	98
	5.6 运行第一条Pig命令	99
	5.7 使用Pig执行集合操作（join，union）与排序	100
	5.8 安装Hive	102
	5.9 使用Hive运行SQL风格的查询	103
	5.10 使用Hive执行join	105
	5.11 安装Mahout	107
	5.12 使用Mahout运行K-means	108
	5.13 可视化K-means结果	110

### 第6章 分析	112
	6.1 简介	112
	6.2 使用MapReduce的简单分析	113
	6.3 使用MapReduce执行Group-By	116
	6.4 使用MapReduce计算频率分布和排序	119
	6.5 使用GNU Plot绘制Hadoop计算结果	121
	6.6 使用MapReduce计算直方图	123
	6.7 使用MapReduce计算散点图	126
	6.8 用Hadoop解析复杂的数据集	129
	6.9 使用MapReduce连接两个数据集	133

### 第7章 搜索和索引	139
	7.1 简介	139
	7.2 使用Hadoop MapReduce生成倒排索引	140
	7.3 使用Apache Nutch构建域内网络爬虫	143
	7.4 使用Apache Solr索引和搜索网络文档	147
	7.5 配置Apache HBase作为ApacheNutch的后端数据存储	149
	7.6 在Hadoop集群上部署Apache HBase	151
	7.7 使用Hadoop/HBase集群构建Apache Nutch全网爬虫服务	153
	7.8 用于索引和搜索的ElasticSearch	156
	7.9 生成抓取网页的内链图	158

### 第8章 聚类、推荐和关系发现	161
	8.1 简介	161
	8.2 基于内容的推荐	162
	8.3 层次聚类	167
	8.4 对亚马逊销售数据集进行聚类操作	170
	8.5 基于协同过滤的推荐	173
	8.6 使用朴素贝叶斯分类器的分类	176
	8.7 使用Adwords平衡算法给广告分配关键字	181

### 第9章 海量文本数据处理	189
	9.1 简介	189
	9.2 使用Hadoop Streaming和Python预处理数据（抽取、清洗和格式转换）	190
	9.3 使用Hadoop Streaming进行数据去重	192
	9.4 使用importtsv和批量加载工具把大型数据集加载到ApacheHBase数据存储中	194
	9.5 创建用于文本数据的TF向量和TF-IDF向量	198
	9.6 聚类文本数据	201
	9.7 使用隐含狄利克雷分布（LDA）发现主题	203
	9.8 使用Mahout的朴素贝叶斯分类器分类文件	206

### 第10章 云端部署——在云上使用Hadoop	208
	10.1 简介	208
	10.2 使用亚马逊弹性MapReduce运行Hadoop MapReduce计算	209
	10.3 使用亚马逊EC2竞价实例来执行EMR作业流以节约开支	212
	10.4 使用EMR执行Pig脚本	213
	10.5 使用EMR执行Hive脚本	216
	10.6 使用命令行界面创建亚马逊EMR作业流	219
	10.7 使用EMR在亚马逊EC2云上部署Apache HBase集群	222
	10.8 使用EMR引导操作来配置亚马逊EMR作业的虚拟机	226
	10.9 使用Apache Whirr在云环境中部署Apache Hadoop集群	228
	10.10 使用Apache Whirr在云环境中部署Apache HBase集群	231 