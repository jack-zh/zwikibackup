tags: 
title: 《Hadoop硬实战》 -目录

## 第1 部分 背景和基本原理 1 

	1 跳跃中的Hadoop 3 
	1.1 什么是Hadoop 4 
	1.1.1 Hadoop 的核心组件 5 
	1.1.2 Hadoop 生态圈 9 
	1.1.3 物理架构 10 
	1.1.4 谁在使用Hadoop 12 
	1.1.5 Hadoop 的局限性 13 
	1.2 运行Hadoop 14 
	1.2.1 下载并安装Hadoop 14 
	1.2.2 Hadoop 的配置 15 
	1.2.3 CLI 基本命令 17 
	1.2.4 运行MapReduce 作业 18 
	1.3 本章小结 24 

## 第2 部分 数据逻辑 25 

### 2 将数据导入导出Hadoop 27 	
	2.1 导入导出的关键要素 29 
	2.2 将数据导入Hadoop 30 
	2.2.1 将日志文件导入Hadoop 31 
	技术点1 使用Flume 将系统日志文件导入HDFS 33 
	2.2.2 导入导出半结构化和二进制文件 42 
	技术点2 自动复制文件到HDFS 的机制 43 
	技术点3 使用Oozie 定期执行数据导入活动 48 
	2.2.3 从数据库中拉数据 52 
	技术点4 使用MapReduce 将数据导入数据库 53 
	技术点5 使用Sqoop 从MySQL 导入数据 58 
	2.2.4 HBase 68 
	技术点6 HBase 导入HDFS 68 
	技术点7 将HBase 作为MapReduce 的数据源 70 
	2.3 将数据导出Hadoop 73 
	2.3.1 将数据导入本地文件系统 73 
	技术点8 自动复制HDFS 中的文件 73 
	2.3.2 数据库 74 
	技术点9 使用Sqoop 将数据导入MySQL 75 
	2.3.3 Hbase 78 
	技术点10 将数据从HDFS 导入HBase 78 
	技术点11 使用HBase 作为MapReduce 的数据接收器 79 
	2.4 本章小结 81 

### 3 数据序列化——处理文本文件及其他格式的文件 83 
	3.1 了解MapReduce 中的输入和输出 84 
	3.1.1 数据输入 85 
	3.1.2 数据输出 89 
	3.2 处理常见的序列化格式 91 
	3.2.1 XML 91 
	技术点12 MapReduce 和XML 91 
	3.2.2 JSON 95 
	技术点13 MapReduce 和JSON 95 
	3.3 大数据的序列化格式 99 
	3.3.1 比较SequenceFiles、Protocol Buffers、Thrift 和 Avro 99 
	3.3.2 Sequence File 101 
	技术点14 处理SequenceFile 103 
	3.3.3 Protocol Buffers 109 
	技术点15 整合Protocol Buffers 和MapReduce 110 
	3.3.4 Thrift 117 
	技术点16 使用Thrift 117 
	3.3.5 Avro 119 
	技术点17 MapReduce 的下一代数据序列化技术 120 
	3.4 自定义文件格式 127 
	3.4.1 输入输出格式 127 
	技术点18 输入和输出格式为CSV 的文件 128 
	3.4.2 output committing 的重要性 136 
	3.5 本章小结 136 

## 第3 部分 大数据模式 137 

### 4 处理大数据的MapReduce 模式 139 
	4.1 Join 140 
	4.1.1 Repartition Join 141 
	技术点19 优化repartition join 142 
	4.1.2 Replicated Join 146 
	4.1.3 Semi-join 147 
	技术点20 实现semi-join 148 
	4.1.4 为你的数据挑选最优的合并策略 154 
	4.2 排序 155 
	4.2.1 二次排序 156 
	技术点21 二次排序的实现 157 
	4.2.2 整体并行排序 162 
	技术点22 通过多个reducer 对key 进行排序 162 
	4.3 抽样 165 
	技术点23 蓄水池抽样（reservoir 抽样） 165 
	4.4 本章小结 168 

### 5 优化HDFS 处理大数据的技术 169 
	5.1 处理小文件 170 
	技术点24 使用Avro 存储大量小文件 170 
	5.2 通过压缩提高数据存储效率 178 
	技术点25 选择合适的压缩解码器 178 
	技术点26 在HDFS、MapReduce、Pig 和Hive 中使用数据压缩 182 
	技术点27 在MapReduce、Hive 和Pig 中处理可分割的LZOP 187 
	5.3 本章小结 193 

### 6 诊断和优化性能问题 194 
	6.1 衡量MapReduce 和你的环境 195 
	6.1.1 提取作业统计信息的工具 195 
	6.1.2 监控 196 
	6.2 确定性能问题的原因 198 
	6.2.1 了解哪些因素会影响MapReduce 作业的性能 198 
	6.2.2 map 端异常 200 
	技术点28 发现输入数据中的坑 200 
	技术点29 确定map 端数据倾斜问题 201 
	技术点30 判定map 任务吞吐量 203 
	技术点31 小文件 204 
	技术点32 不可切割的文件 206 
	6.2.3 reduce 端问题 207 
	技术点33 reducer 任务数过大或过小 208 
	技术点34 定位reduce 端数据倾斜问题 209 
	技术点35 确定reduce 任务是否存在整体吞吐量过低 211 
	技术点36 缓慢的洗牌（shuffle）和排序 213 
	6.2.4 任务的一般性能问题 213 
	技术点37 作业竞争和调度器限制 215 
	技术点38 使用堆转储来查找未优化的用户代码 216 
	6.2.5 硬件性能问题 218 
	技术点39 查找硬件的失效 218 
	技术点40 CPU 竞争 219 
	技术点41 内存交换 220 
	技术点42 磁盘健康 222 
	技术点43 网络 224 
	6.3 可视化 226 
	技术点44 提取并可视化任务执行时间 227 
	6.4 优化 229 
	6.4.1 剖析MapReduce 的用户代码 230 
	技术点45 剖析map 和reduce 任务 230 
	6.4.2 参数配置 232 
	6.4.3 优化 shuffle 和 sort 阶段 234 
	技术点46 避免reducer 234 
	技术点47 过滤和投影 235 
	技术点48 使用 combiner 236 
	技术点49 超炫的使用比较器的快速排序 237 
	6.4.4 减轻倾斜 241 
	技术点50 收集倾斜数据 242 
	技术点51 减轻reducer 阶段倾斜 243 
	6.4.5 在MapReduce 中优化用户的Java 代码 244 
	6.4.6 数据序列化 248 
	6.5 本章小结 249 

## 第4 部分 数据科学 251 

### 7 数据结构和算法的运用 253 
	7.1 使用图进行数据建模和解决问题 254 
	7.1.1 模拟图 255 
	7.1.2 最短路径算法 255 
	技术点52 找出两个用户间的最短距离 256 
	7.1.3 friends-of-friends（FoF） 263 
	技术点53 计算FoF 263 
	7.1.4 PageRank 269 
	技术点54 通过Web 图计算PageRank 269 
	7.2 Bloom filter 275 
	技术点55 在MapReduce 中并行创建Bloom filter 277 
	技术点56 通过MapReduce 对Bloom filter 进行semi-join 281 
	7.3 本章小结 284 

### 8 结合R 和Hadoop 进行数据统计 285 
	8.1 比较R 和MapReduce 集成的几种方法 286 
	8.2 R 基础知识 288 
	8.3 R 和Streaming 290 
	8.3.1 Streaming 和map-only R 290 
	技术点57 计算股票日平均值 290 
	8.3.2 Streaming、R 和完整的MapReduce 293 
	技术点58 计算股票的累积均值 293 
	8.4 Rhipe——将客户端R 和Hadoop 进行集成 297 
	技术点59 使用Rhipe 计算CMA 297 
	8.5 RHadoop——更简单地在客户端集成R 和Hadoop 的技术 301 
	技术点60 使用RHadoop 计算CMA 302 
	8.6 本章小结 304 

### 9 使用Mahout 进行预测分析 305 
	9.1 使用recommender 提供产品建议 306 
	9.1.1 相似性度量的可视化 307 
	9.1.2 GroupLens 数据集 308 
	9.1.3 基于用户的recommender 310 
	9.1.4 基于物品的recommender 310 
	技术点61 使用基于物品的recommender 进行电影评级 311 
	9.2 classification 314 
	9.2.1 编写一个手动na?ve Bayesian 分类器 315 
	9.2.2 可扩展的垃圾邮件侦测分类系统 321 
	技术点62 使用Mahout 训练和测试垃圾邮件分类器 321 
	9.2.3 其他分类算法 325 
	9.3 K-means clustering 325 
	9.3.1 简单介绍 326 
	9.3.2 并行执行K-means 327 
	技术点63 K-means 处理合成的二维数据集 327 
	9.3.3 K-means 和文本 331 
	9.3.4 其他Mahout clustering 算法 332 
	9.4 本章小结 332 

## 第5 部分 驯服大象 333 

### 10 深入解析 Hive 335 
	10.1 Hive 基础 336 
	10.1.1 安装 336 
	10.1.2 元存储 336 
	10.1.3 数据库、表、分区和存储 336 
	10.1.4 数据模型 337 
	10.1.5 查询语言 337 
	10.1.6 交互式和非交互式Hive 337 
	10.2 使用Hive 进行数据分析 338 
	10.2.1 序列化和反序列化 338 
	技术点64 载入日志文件 338 
	10.2.2 UDF、分区、分桶和压缩 344 
	技术点65 编写UDF 和压缩分区表 344 
	10.2.3 数据合并 350 
	技术点66 优化Hive 合并 350 
	10.2.4 分组、排序和explain 355 
	10.3 本章小结 358 

### 11 Pig 流管道 359 
	11.1 Pig 基础 360 
	11.1.1 安装 360 
	11.1.2 架构 360 
	11.1.3 PigLatin 360 
	11.1.4 数据类型 361 
	11.1.5 操作符和函数 361 
	11.1.6 交互式和非交互式的Pig 362 
	11.2 使用Pig 在日志数据中发现恶意行为者 362 
	11.2.1 加载数据 363 
	技术点67 加载Apache 日志文件 363 
	11.2.2 过滤和投影 368 
	技术点68 通过过滤和投影减少数据处理量 368 
	11.2.3 分组和聚合UDF 370 
	技术点69 IP 地址的分组和计数 370 
	11.2.4 使用UDF 进行定位 374 
	技术点70 使用分布式缓存进行IP 地理定位 375 
	11.2.5 流 378 
	技术点71 使用你的脚本合并Pig 378 
	11.2.6 合并 379 
	技术点72 在Pig 中合并数据 380 
	11.2.7 排序 381 
	技术点73 元组排序 381 
	11.2.8 存储数据 382 
	技术点74 在SequenceFiles 中存储数据 382 
	11.3 使用Pig 优化用户的工作流程 385 
	技术点75 通过4 步快速处理大数据 385 
	11.4 性能 390 
	技术点76 Pig 优化 390 
	11.5 本章小结 393 

### 12 Crunch 及相关技术 394 
	12.1 什么是Crunch 395 
	12.1.1 背景和概念 395 
	12.1.2 基本原理 395 
	12.1.3 简单示例 398 
	12.2 发现日志中最热门的URL 401 
	技术点77 使用Crunch 进行日志解析和基本分析 402 
	12.3 合并 405 
	技术点78 Crunch 的repartition join 405 
	12.4 Cascading 407 
	12.5 本章小结 409 

### 13 测试和调试 410 
	13.1 测试 410 
	13.1.1 有效的单元测试的基本要素 411 
	13.1.2 MRUnit 413 
	技术点79 MapReduce 函数、作业和管道的单元测试 413 
	13.1.3 LocalJobRunner 420 
	技术点80 用LocalJobRunner 进行重量级的作业测试 421 
	13.1.4 集成和QA 测试 423 
	13.2 调试用户空间的问题 424 
	13.2.1 访问任务日志 424 
	技术点81 检查任务日志 424 
	13.2.2 调试不可预期的输入 429 
	技术点82 定位input split 问题 429 
	13.2.3 调试JVM 配置 432 
	技术点83 解决任务的JVM 启动参数 433 
	13.2.4 高效调试的编码准则 433 
	技术点84 调试和错误处理 433 
	13.3 MapReduce 陷阱 437 
	技术点85 MapReduce 反模式 438 
	13.4 本章小结 441 

#### 附录A 相关技术 443 
#### 附录B Hadoop 内置的数据导入导出工具 471 
#### 附录C HDFS 解剖 486 
#### 附录D 优化MapReduce 合并框架 493 
#### 索引 503 
